#!/usr/bin/env python3
"""
Exemplo 9: An√°lise de escalabilidade de opera√ß√µes vetoriais
Demonstra strong e weak scaling para compreender limites de paraleliza√ß√£o.
"""

import time
import numpy as np
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor, as_completed
import matplotlib.pyplot as plt

def vector_operation_worker(args):
    """Worker para opera√ß√µes vetoriais complexas"""
    start_idx, end_idx, data = args
    # Simular opera√ß√£o complexa: m√∫ltiplas opera√ß√µes matem√°ticas
    chunk = data[start_idx:end_idx]
    result = np.sum(chunk**2) + np.sum(np.sin(chunk)) + np.sum(np.cos(chunk))
    return result

def scaling_study_strong(vector_size, max_processes):
    """
    Strong scaling: tamanho fixo, aumentar processos
    """
    print(f"\nüìä Strong Scaling - Tamanho fixo: {vector_size:,} elementos")
    print("-" * 60)
    
    # Gerar dados
    np.random.seed(42)
    data = np.random.randn(vector_size)
    
    results = []
    
    for n_proc in range(1, max_processes + 1):
        # Dividir trabalho
        chunk_size = vector_size // n_proc
        
        start_time = time.perf_counter()
        
        if n_proc == 1:
            # Serial
            total = vector_operation_worker((0, vector_size, data))
        else:
            # Paralelo
            with ProcessPoolExecutor(max_workers=n_proc) as executor:
                futures = []
                for i in range(n_proc):
                    start_idx = i * chunk_size
                    end_idx = start_idx + chunk_size if i < n_proc - 1 else vector_size
                    future = executor.submit(vector_operation_worker, (start_idx, end_idx, data))
                    futures.append(future)
                
                total = sum(future.result() for future in as_completed(futures))
        
        exec_time = time.perf_counter() - start_time
        
        if n_proc == 1:
            serial_time = exec_time
            speedup = 1.0
            efficiency = 1.0
        else:
            speedup = serial_time / exec_time
            efficiency = speedup / n_proc
        
        results.append({
            'processes': n_proc,
            'time': exec_time,
            'speedup': speedup,
            'efficiency': efficiency
        })
        
        print(f"  {n_proc:2d} processos: {exec_time:.4f}s, speedup: {speedup:.2f}x, efici√™ncia: {efficiency:.2f}")
    
    return results

def scaling_study_weak(base_size_per_process, max_processes):
    """
    Weak scaling: trabalho por processo fixo, aumentar processos
    """
    print(f"\nüìà Weak Scaling - {base_size_per_process:,} elementos por processo")
    print("-" * 60)
    
    results = []
    serial_time = None
    
    for n_proc in range(1, max_processes + 1):
        vector_size = base_size_per_process * n_proc
        
        # Gerar dados
        np.random.seed(42)
        data = np.random.randn(vector_size)
        
        start_time = time.perf_counter()
        
        if n_proc == 1:
            # Serial
            total = vector_operation_worker((0, vector_size, data))
            serial_time = time.perf_counter() - start_time
            speedup = 1.0
            efficiency = 1.0
        else:
            # Paralelo
            chunk_size = vector_size // n_proc
            
            with ProcessPoolExecutor(max_workers=n_proc) as executor:
                futures = []
                for i in range(n_proc):
                    start_idx = i * chunk_size
                    end_idx = start_idx + chunk_size if i < n_proc - 1 else vector_size
                    future = executor.submit(vector_operation_worker, (start_idx, end_idx, data))
                    futures.append(future)
                
                total = sum(future.result() for future in as_completed(futures))
            
            exec_time = time.perf_counter() - start_time
            # Para weak scaling, efici√™ncia ideal √© tempo constante
            efficiency = serial_time / exec_time if exec_time > 0 else 0
            speedup = efficiency * n_proc
        
        if n_proc > 1:
            exec_time = time.perf_counter() - start_time
        else:
            exec_time = serial_time
        
        results.append({
            'processes': n_proc,
            'problem_size': vector_size,
            'time': exec_time,
            'speedup': speedup,
            'efficiency': efficiency
        })
        
        print(f"  {n_proc:2d} processos ({vector_size:7,} elementos): {exec_time:.4f}s, efici√™ncia: {efficiency:.2f}")
    
    return results

def plot_scaling_results(strong_results, weak_results):
    """Criar gr√°ficos de escalabilidade"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # Strong scaling - Speedup
    processes = [r['processes'] for r in strong_results]
    speedups = [r['speedup'] for r in strong_results]
    ideal_speedup = processes
    
    ax1.plot(processes, speedups, 'bo-', label='Speedup Real', linewidth=2, markersize=8)
    ax1.plot(processes, ideal_speedup, 'r--', label='Speedup Ideal', linewidth=2)
    ax1.set_xlabel('N√∫mero de Processos')
    ax1.set_ylabel('Speedup')
    ax1.set_title('Strong Scaling - Speedup')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_xticks(processes)
    
    # Strong scaling - Efici√™ncia
    efficiencies = [r['efficiency'] for r in strong_results]
    
    ax2.plot(processes, efficiencies, 'go-', linewidth=2, markersize=8)
    ax2.axhline(y=1.0, color='r', linestyle='--', alpha=0.7)
    ax2.set_xlabel('N√∫mero de Processos')
    ax2.set_ylabel('Efici√™ncia')
    ax2.set_title('Strong Scaling - Efici√™ncia')
    ax2.grid(True, alpha=0.3)
    ax2.set_xticks(processes)
    ax2.set_ylim(0, 1.1)
    
    # Weak scaling - Tempo
    weak_processes = [r['processes'] for r in weak_results]
    weak_times = [r['time'] for r in weak_results]
    
    ax3.plot(weak_processes, weak_times, 'mo-', linewidth=2, markersize=8)
    ax3.axhline(y=weak_times[0], color='r', linestyle='--', alpha=0.7, label='Tempo Ideal')
    ax3.set_xlabel('N√∫mero de Processos')
    ax3.set_ylabel('Tempo de Execu√ß√£o (s)')
    ax3.set_title('Weak Scaling - Tempo')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    ax3.set_xticks(weak_processes)
    
    # Weak scaling - Efici√™ncia
    weak_efficiencies = [r['efficiency'] for r in weak_results]
    
    ax4.plot(weak_processes, weak_efficiencies, 'co-', linewidth=2, markersize=8)
    ax4.axhline(y=1.0, color='r', linestyle='--', alpha=0.7)
    ax4.set_xlabel('N√∫mero de Processos')
    ax4.set_ylabel('Efici√™ncia')
    ax4.set_title('Weak Scaling - Efici√™ncia')
    ax4.grid(True, alpha=0.3)
    ax4.set_xticks(weak_processes)
    ax4.set_ylim(0, 1.1)
    
    plt.tight_layout()
    plt.savefig('scaling_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def main():
    print("üî¨ An√°lise de Escalabilidade de Opera√ß√µes Vetoriais")
    print("=" * 60)
    
    max_proc = min(mp.cpu_count(), 8)  # Limitar para an√°lise
    print(f"Sistema: {mp.cpu_count()} n√∫cleos, testando at√© {max_proc} processos")
    
    # Strong scaling
    strong_results = scaling_study_strong(1_000_000, max_proc)
    
    # Weak scaling
    weak_results = scaling_study_weak(250_000, max_proc)
    
    # An√°lise dos resultados
    print("\nüìã Resumo da An√°lise:")
    print(f"‚Ä¢ Strong scaling m√°ximo: {max(r['speedup'] for r in strong_results):.2f}x")
    print(f"‚Ä¢ Efici√™ncia final (strong): {strong_results[-1]['efficiency']:.2f}")
    print(f"‚Ä¢ Efici√™ncia final (weak): {weak_results[-1]['efficiency']:.2f}")
    
    # Detectar overhead
    overhead_start = None
    for i, result in enumerate(strong_results):
        if result['efficiency'] < 0.8:  # Efici√™ncia abaixo de 80%
            overhead_start = result['processes']
            break
    
    if overhead_start:
        print(f"‚Ä¢ Overhead significativo a partir de {overhead_start} processos")
    else:
        print("‚Ä¢ Escalabilidade boa em todos os n√≠veis testados")
    
    print("\nüí° Interpreta√ß√£o:")
    print("‚Ä¢ Strong scaling: performance com problema fixo")
    print("‚Ä¢ Weak scaling: performance com trabalho/processo fixo")
    print("‚Ä¢ Efici√™ncia ideal = 1.0 (100%)")
    print("‚Ä¢ Overhead reduz efici√™ncia para muitos processos")
    
    print("\nüìä Gerando gr√°ficos...")
    try:
        plot_scaling_results(strong_results, weak_results)
        print("‚úì Gr√°ficos salvos como 'scaling_analysis.png'")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erro ao gerar gr√°ficos: {e}")
    
    print("\nüéØ Aplica√ß√µes em Engenharia:")
    print("‚Ä¢ Dimensionamento de clusters computacionais")
    print("‚Ä¢ Escolha do n√∫mero ideal de processos")
    print("‚Ä¢ Identifica√ß√£o de gargalos de paraleliza√ß√£o")
    print("‚Ä¢ Previs√£o de performance em sistemas maiores")

if __name__ == "__main__":
    main()