# üß© Aula 1 ‚Äì Pensando em Paralelismo e Performance (CPU)

**Computa√ß√£o de Alto Desempenho em Python para Engenharia Civil**

---

## üìã Agenda da Aula

1. **Motiva√ß√£o:** Por que HPC em Engenharia Civil?
2. **Conceitos Fundamentais** de Paralelismo
3. **Python e o GIL** - Limita√ß√µes e Solu√ß√µes
4. **Multiprocessing** em Python
5. **M√©tricas de Performance**
6. **Aplica√ß√µes Pr√°ticas** - Demonstra√ß√µes
7. **Exerc√≠cios e Discuss√£o**

---

## üéØ Por que Engenheiros Civis precisam de HPC?

### Problemas Computacionalmente Intensivos

- **üèóÔ∏è An√°lise Estrutural (FEM)**
  - Matrizes de rigidez enormes (milh√µes de DOF)
  - An√°lise din√¢mica e n√£o-linear
  - Otimiza√ß√£o de design

- **üåä Mec√¢nica dos Fluidos (CFD)**
  - Simula√ß√£o de vento em edif√≠cios
  - An√°lise de barragens e vertedouros
  - Transporte de sedimentos

- **üî• Transfer√™ncia de Calor**
  - An√°lise t√©rmica de estruturas
  - Comportamento ao fogo
  - Conforto t√©rmico

- **üìä An√°lise Probabil√≠stica**
  - Monte Carlo para confiabilidade
  - An√°lise de risco s√≠smico
  - Variabilidade de materiais

---

## üìà O Crescimento dos Problemas

### Lei de Moore vs. Realidade Atual

```
D√©cada de 1990: Frequ√™ncia da CPU dobrava a cada 2 anos
Hoje: Frequ√™ncias estagnadas (~3-4 GHz)
Solu√ß√£o: MAIS N√öCLEOS!
```

### Escalabilidade dos Problemas

| Resolu√ß√£o da Malha | Elementos | Tempo Serial | Mem√≥ria |
|-------------------|-----------|--------------|---------|
| Grosseira         | 10¬≥       | segundos     | MB      |
| M√©dia             | 10‚Å∂       | minutos      | GB      |
| Fina              | 10‚Åπ       | dias/semanas | TB      |

**üí° Quest√£o:** *O que acontece se eu dobrar a resolu√ß√£o da minha malha?*

---

## üîÑ Conceitos Fundamentais de Paralelismo

### Computa√ß√£o Serial vs Paralela

#### Serial (Tradicional)
```
Tarefa A ‚Üí Tarefa B ‚Üí Tarefa C ‚Üí Tarefa D
         (tempo total = t_A + t_B + t_C + t_D)
```

#### Paralela (Objetivo)
```
N√∫cleo 1: Tarefa A
N√∫cleo 2: Tarefa B  ‚Üê Executando simultaneamente
N√∫cleo 3: Tarefa C
N√∫cleo 4: Tarefa D
         (tempo total ‚âà max(t_A, t_B, t_C, t_D))
```

### Lei de Amdahl

**F√≥rmula:** `Speedup = 1 / (S + (1-S)/P)`

Onde:
- **S** = fra√ß√£o serial do c√≥digo (n√£o paraleliz√°vel)
- **P** = n√∫mero de processadores
- **1-S** = fra√ß√£o paraleliz√°vel

**Implica√ß√£o:** Mesmo com infinitos processadores, speedup ‚â§ 1/S

![Lei de Amdahl](figures/amdahl_law.png)

---

## üêç Python e o Global Interpreter Lock (GIL)

### O Problema do GIL

```python
# ‚ùå Threading em Python - N√ÉO funciona para CPU intensivo
import threading

def trabalho_pesado():
    for i in range(10**7):
        i * i * i  # Opera√ß√£o CPU intensiva

# Mesmo com threads, apenas 1 thread executa de cada vez!
```

### Por que o GIL existe?

1. **Simplifica** o desenvolvimento do interpretador Python
2. **Protege** estruturas internas de condi√ß√µes de corrida
3. **Facilita** integra√ß√£o com bibliotecas C
4. **Evita** problemas de sincroniza√ß√£o complexos

### Solu√ß√µes para Contornar o GIL

| Abordagem | Quando Usar | Limita√ß√µes |
|-----------|-------------|------------|
| **Threading** | I/O intensivo | N√£o para CPU |
| **Multiprocessing** | CPU intensivo | Overhead de comunica√ß√£o |
| **NumPy/SciPy** | Opera√ß√µes vetorizadas | GIL liberado automaticamente |
| **Numba/Cython** | Loops pesados | Compila√ß√£o necess√°ria |

![Threading vs Multiprocessing](figures/threading_vs_multiprocessing.png)

---

## ‚öôÔ∏è Multiprocessing em Python

### Conceitos Chave

#### Processo vs Thread
- **Processo:** Espa√ßo de mem√≥ria separado, overhead maior
- **Thread:** Compartilha mem√≥ria, menor overhead, limitado pelo GIL

#### Tipos de Paralelismo
1. **Task Parallelism:** Tarefas diferentes em paralelo
2. **Data Parallelism:** Mesma opera√ß√£o em dados diferentes

### Ferramentas Principais

```python
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor

# M√©todo 1: Pool de processos
with mp.Pool(processes=4) as pool:
    resultados = pool.map(funcao, dados)

# M√©todo 2: ProcessPoolExecutor (mais moderno)
with ProcessPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(funcao, dado) for dado in dados]
    resultados = [future.result() for future in futures]
```

---

## üìä M√©tricas de Performance

### Speedup
```
Speedup = Tempo_Serial / Tempo_Paralelo
```

- **Speedup = P** (ideal, onde P = n√∫mero de processos)
- **Speedup < P** (real, devido a overhead)

### Efici√™ncia
```
Efici√™ncia = Speedup / P
```

- **100%** = paraleliza√ß√£o perfeita
- **< 100%** = h√° overhead e gargalos

### Strong vs Weak Scaling

#### Strong Scaling
- Problema **fixo**, varia n√∫mero de processadores
- Objetivo: reduzir tempo total
- Limitado pela Lei de Amdahl

#### Weak Scaling
- Trabalho **por processador** fixo
- Objetivo: resolver problemas maiores
- Pode manter efici√™ncia constante

![Performance Scaling](figures/performance_scaling.png)

---

## üî¢ Exemplo 1: Soma de Vetores

### Teoria: Data Parallelism

```
Vetor A = [a‚ÇÅ, a‚ÇÇ, a‚ÇÉ, a‚ÇÑ, a‚ÇÖ, a‚ÇÜ, a‚Çá, a‚Çà]
Vetor B = [b‚ÇÅ, b‚ÇÇ, b‚ÇÉ, b‚ÇÑ, b‚ÇÖ, b‚ÇÜ, b‚Çá, b‚Çà]

Serial: A + B elemento por elemento

Paralelo (2 processos):
Processo 1: [a‚ÇÅ+b‚ÇÅ, a‚ÇÇ+b‚ÇÇ, a‚ÇÉ+b‚ÇÉ, a‚ÇÑ+b‚ÇÑ]
Processo 2: [a‚ÇÖ+b‚ÇÖ, a‚ÇÜ+b‚ÇÜ, a‚Çá+b‚Çá, a‚Çà+b‚Çà]
```

![Data Parallelism](figures/data_parallelism.png)

### Aplica√ß√£o em Engenharia
- Soma de for√ßas nodais em FEM
- Opera√ß√µes vetoriais em an√°lise estrutural
- Processamento de dados de sensores

**‚Üí Demonstra√ß√£o no Notebook**

---

## üé≤ Exemplo 2: Monte Carlo para œÄ

### Teoria: M√©todos Probabil√≠sticos

```
œÄ ‚âà 4 √ó (pontos_dentro_c√≠rculo / total_pontos)

C√≠rculo: x¬≤ + y¬≤ ‚â§ 1
Quadrado: -1 ‚â§ x,y ‚â§ 1
```

![Monte Carlo Visualization](figures/monte_carlo_visualization.png)

### Paraleliza√ß√£o
- Cada processo gera amostras independentes
- Sem depend√™ncias entre processos
- "Embarrassingly parallel"

### Aplica√ß√£o em Engenharia
- **An√°lise de confiabilidade** estrutural
- **Simula√ß√£o de carregamentos** aleat√≥rios  
- **An√°lise de incertezas** em materiais

**‚Üí Demonstra√ß√£o no Notebook**

---

## üî¢ Exemplo 3: Multiplica√ß√£o de Matrizes

### Teoria: √Ålgebra Linear Paralela

```
C = A √ó B

C[i,j] = Œ£(A[i,k] √ó B[k,j])

Paraleliza√ß√£o por linhas:
Processo 1: calcula linhas 1-n/4 de C
Processo 2: calcula linhas n/4+1-n/2 de C
...
```

### Aplica√ß√£o em Engenharia
- **Sistema Ku = F** (an√°lise estrutural)
- **Autovalores** para an√°lise modal
- **Opera√ß√µes** em grande escala

**‚Üí Demonstra√ß√£o no Notebook**

---

## üèóÔ∏è Exemplo 4: An√°lise Estrutural Simplificada

### Teoria: An√°lise de Vigas

Para viga simplesmente apoiada com carga central P:

```
Deflex√£o m√°xima: Œ¥ = P√óL¬≥/(48√óE√óI)
Momento m√°ximo:   M = P√óL/4
Tens√£o m√°xima:    œÉ = M√óc/I
```

### Paraleliza√ß√£o
- Analisar **m√∫ltiplas vigas** simultaneamente
- Cada processo: par√¢metros diferentes (P, L, E, I)
- An√°lise param√©trica eficiente

### Aplica√ß√£o Pr√°tica
- **Dimensionamento** otimizado
- **An√°lise de sensibilidade**
- **Verifica√ß√£o** de c√≥digos normativos

**‚Üí Demonstra√ß√£o no Notebook**

---

## üí° Boas Pr√°ticas

### ‚úÖ Quando Usar Multiprocessing

1. **CPU intensivo:** Loops pesados, c√°lculos matem√°ticos
2. **Dados independentes:** Podem ser processados separadamente
3. **Overhead aceit√°vel:** Tempo de execu√ß√£o > tempo de setup

### ‚ùå Quando N√ÉO Usar

1. **I/O intensivo:** Use threading ou async
2. **Pouco trabalho:** Overhead > benef√≠cio
3. **Mem√≥ria limitada:** Cada processo consome RAM

### Otimiza√ß√µes

```python
# ‚úÖ Bom: reutilizar pool
with ProcessPoolExecutor(max_workers=4) as executor:
    for batch in data_batches:
        executor.map(process_batch, batch)

# ‚ùå Ruim: criar processo para cada tarefa pequena
for item in small_items:
    executor.submit(process_item, item)
```

---

## üéØ Pontos Principais para Recordar

### Conceitos Te√≥ricos
1. **Lei de Amdahl** limita speedup m√°ximo
2. **GIL** impede paralelismo real com threads
3. **Multiprocessing** contorna GIL com overhead

### Implementa√ß√£o Pr√°tica
1. **ProcessPoolExecutor** √© mais moderno que Pool
2. **Medi√ß√£o** √© essencial: sempre compare performance
3. **Tamanho do problema** determina efic√°cia

### Aplica√ß√µes
1. **Data parallelism** funciona bem em engenharia
2. **Monte Carlo** √© naturalmente paralelo
3. **√Ålgebra linear** tem muitas oportunidades

---

## üöÄ Pr√≥ximos Passos

### Nesta Aula
- Praticar com exemplos do notebook
- Medir speedup e efici√™ncia
- Entender limita√ß√µes e overhead

### Pr√≥xima Aula
- **Ferramentas avan√ßadas:** joblib, numba
- **Scaling studies** detalhados
- **Otimiza√ß√£o** de c√≥digo Python

### Para Casa
- Aplicar multiprocessing em problema pr√≥prio
- Experimentar com diferentes n√∫meros de processos
- Documentar resultados de performance

---

## ‚ùì Perguntas e Discuss√£o

**Quest√µes para reflex√£o:**

1. Como identificar gargalos em meu c√≥digo?
2. Qual o n√∫mero ideal de processos?
3. Como adaptar algoritmos existentes?
4. Quando vale a pena paralelizar?

**Desafio:** Pense em um problema da sua √°rea de pesquisa que poderia se beneficiar de paraleliza√ß√£o!

---

**Vamos para o Notebook! üíª**