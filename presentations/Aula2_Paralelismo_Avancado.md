# ‚öôÔ∏è Aula 2 ‚Äì Paralelismo Avan√ßado e Escalabilidade

**Computa√ß√£o de Alto Desempenho em Python para Engenharia Civil**

---

## üìã Agenda da Aula

1. **Revis√£o** - Conceitos da Aula 1
2. **Medi√ß√£o de Performance** Profissional
3. **concurrent.futures** Avan√ßado
4. **Joblib** - Paraleliza√ß√£o Simplificada
5. **Numba** - Compila√ß√£o JIT
6. **Scaling Studies** - Strong vs Weak
7. **Casos Reais** de Otimiza√ß√£o
8. **Boas Pr√°ticas** e Pitfalls

---

## üîÑ Revis√£o: Fundamentos

### O que Aprendemos na Aula 1

#### Conceitos Principais
- **Paralelismo** quebra GIL do Python
- **Multiprocessing** para CPU intensivo  
- **Lei de Amdahl** limita speedup
- **Data parallelism** funciona bem

#### Ferramentas B√°sicas
```python
from concurrent.futures import ProcessPoolExecutor

with ProcessPoolExecutor(max_workers=4) as executor:
    results = executor.map(function, data)
```

### Limita√ß√µes Identificadas

1. **Overhead** de cria√ß√£o de processos
2. **Comunica√ß√£o** entre processos cara
3. **Mem√≥ria** duplicada por processo
4. **Setup complexo** para casos simples

**‚Üí Como podemos melhorar?**

---

## üìä Medi√ß√£o de Performance Profissional

### Al√©m do `time.time()`

#### Timing Preciso
```python
import timeit

# Para fun√ß√µes r√°pidas
tempo = timeit.timeit(funcao, number=1000)

# Com setup personalizado
tempo = timeit.timeit(
    'funcao(dados)', 
    setup='from modulo import funcao, dados',
    number=100
)
```

#### Profiling Detalhado
```python
import cProfile
import pstats

pr = cProfile.Profile()
pr.enable()
# ... c√≥digo a analisar ...
pr.disable()

stats = pstats.Stats(pr)
stats.sort_stats('cumulative').print_stats(10)
```

### M√©tricas Importantes

| M√©trica | F√≥rmula | Interpreta√ß√£o |
|---------|---------|---------------|
| **Speedup** | T_serial / T_parallel | Acelera√ß√£o obtida |
| **Efici√™ncia** | Speedup / P | Utiliza√ß√£o dos recursos |
| **Overhead** | T_parallel √ó P - T_serial | Tempo perdido |
| **Scaling** | f(P) | Como performa vs recursos |

---

## üîß concurrent.futures Avan√ßado

### Al√©m do `map()`

#### submit() e as_completed()
```python
from concurrent.futures import ProcessPoolExecutor, as_completed

futures = []
with ProcessPoolExecutor() as executor:
    for data in datasets:
        future = executor.submit(process_data, data)
        futures.append(future)
    
    for future in as_completed(futures):
        result = future.result()
        # Processa resultado conforme fica pronto
```

#### Vantagens
- **Controle fino** sobre execu√ß√£o
- **Resultados incrementais** 
- **Error handling** individual
- **Progress tracking** poss√≠vel

### Padr√µes Avan√ßados

#### Map com Argumentos M√∫ltiplos
```python
# Dados de entrada
materials = ['steel', 'concrete', 'wood']
loads = [1000, 2000, 3000]  # kN
factors = [1.5, 1.4, 1.2]

# An√°lise paralela
with ProcessPoolExecutor() as executor:
    results = executor.map(analyze_structure, materials, loads, factors)
```

#### Timeout e Error Handling
```python
from concurrent.futures import TimeoutError

try:
    result = future.result(timeout=30)  # 30 segundos m√°ximo
except TimeoutError:
    print("An√°lise demorou muito!")
except Exception as e:
    print(f"Erro na an√°lise: {e}")
```

---

## üõ†Ô∏è Joblib - Paraleliza√ß√£o Simplificada

### Por que Joblib?

- **Sintaxe simples** como list comprehension
- **Otimizado** para NumPy arrays
- **Menos overhead** que multiprocessing
- **Usado internamente** pelo scikit-learn

### Sintaxe B√°sica

```python
from joblib import Parallel, delayed

# Ao inv√©s de:
results = [expensive_function(x) for x in data]

# Use:
results = Parallel(n_jobs=4)(
    delayed(expensive_function)(x) for x in data
)
```

### Aplica√ß√£o: An√°lise Param√©trica

```python
def analyze_beam(length, load, material_props):
    # An√°lise de viga com par√¢metros espec√≠ficos
    E, I = material_props
    deflection = (load * length**3) / (48 * E * I)
    stress = (load * length) / (4 * I / (height/2))
    return deflection, stress

# An√°lise de 1000 configura√ß√µes diferentes
results = Parallel(n_jobs=-1)(  # -1 = todos os n√∫cleos
    delayed(analyze_beam)(L, P, props) 
    for L, P, props in parameter_combinations
)
```

### Vantagens do Joblib

| Aspecto | multiprocessing | joblib |
|---------|----------------|--------|
| **Sintaxe** | Verbosa | Concisa |
| **NumPy** | Copia arrays | Compartilha mem√≥ria |
| **Overhead** | Alto | Baixo |
| **Flexibilidade** | Alta | M√©dia |

![Joblib vs Multiprocessing](figures/joblib_vs_multiprocessing.png)

---

## üöÄ Numba - Compila√ß√£o Just-In-Time

### O que √© Numba?

- **Compilador JIT** para Python
- **Traduz** Python para c√≥digo nativo
- **Acelera loops** e opera√ß√µes num√©ricas
- **Libera√ß√£o autom√°tica** do GIL

### Decorator M√°gico

```python
from numba import jit, njit

@jit  # Compila√ß√£o JIT b√°sica
def slow_function(x):
    result = 0
    for i in range(x):
        result += i * i
    return result

@njit  # No-Python mode (mais r√°pido)
def fast_function(x):
    result = 0
    for i in range(x):
        result += i * i
    return result
```

### Speedups T√≠picos

| Tipo de C√≥digo | Speedup Esperado |
|----------------|------------------|
| **Loops Python puros** | 10-100x |
| **Opera√ß√µes NumPy** | 1-5x |
| **Fun√ß√µes matem√°ticas** | 50-200x |
| **I/O intensivo** | 1x (sem benef√≠cio) |

![Numba Speedup](figures/numba_speedup.png)

### Paraleliza√ß√£o com Numba

```python
from numba import prange  # Parallel range

@njit(parallel=True)
def parallel_sum(arr):
    total = 0.0
    for i in prange(len(arr)):  # Loop paralelo autom√°tico
        total += arr[i] * arr[i]
    return total
```

### Aplica√ß√£o: Multiplica√ß√£o de Matrizes

```python
@njit(parallel=True)
def matrix_multiply_numba(A, B):
    m, k = A.shape
    k, n = B.shape
    C = np.zeros((m, n))
    
    for i in prange(m):  # Paralelo em i
        for j in range(n):
            for l in range(k):
                C[i, j] += A[i, l] * B[l, j]
    
    return C
```

---

## üìà Scaling Studies - Teoria e Pr√°tica

### Strong Scaling

#### Defini√ß√£o
- **Problema fixo**, aumenta n√∫mero de processadores
- Objetivo: **reduzir tempo** de execu√ß√£o
- Limitado pela **Lei de Amdahl**

#### An√°lise Te√≥rica
```
Speedup(P) = 1 / (S + (1-S)/P)

Onde:
S = fra√ß√£o serial (n√£o paraleliz√°vel)
P = n√∫mero de processadores
1-S = fra√ß√£o paralela
```

#### Efici√™ncia Strong Scaling
```
Efici√™ncia(P) = Speedup(P) / P
```

- **100%**: Paraleliza√ß√£o perfeita (imposs√≠vel na pr√°tica)
- **> 80%**: Excelente
- **> 60%**: Boa
- **< 40%**: Problemas de escalabilidade

### Weak Scaling

#### Defini√ß√£o
- **Trabalho por processador** constante
- Problema total **cresce com P**
- Objetivo: **manter tempo** constante

#### Efici√™ncia Weak Scaling
```
Efici√™ncia_weak = T(1) / T(P)

Onde:
T(1) = tempo com 1 processador
T(P) = tempo com P processadores (problema P vezes maior)
```

![Scaling Efficiency](figures/scaling_efficiency.png)

#### Aplica√ß√£o Pr√°tica
```python
# Strong scaling: problema fixo (matriz 1000x1000)
for num_cores in [1, 2, 4, 8]:
    time_strong = measure_time(multiply_1000x1000, num_cores)

# Weak scaling: problema cresce (N√óN por core)
for num_cores in [1, 2, 4, 8]:
    N = base_size * sqrt(num_cores)  # Mant√©m trabalho/core
    time_weak = measure_time(multiply_NxN, num_cores)
```

---

## üî¨ Casos Reais de Otimiza√ß√£o

### Caso 1: Integra√ß√£o Num√©rica

#### Problema Original
```python
def integrate_trapezoidal_slow(f, a, b, n):
    h = (b - a) / n
    result = 0.5 * (f(a) + f(b))
    for i in range(1, n):
        x = a + i * h
        result += f(x)
    return result * h
```

#### Otimiza√ß√£o Passo a Passo

1. **Vetoriza√ß√£o** com NumPy
2. **Paraleliza√ß√£o** com joblib
3. **Compila√ß√£o** com Numba

#### Resultados T√≠picos
| Vers√£o | Tempo (ms) | Speedup |
|--------|------------|---------|
| Original | 1000 | 1x |
| NumPy | 100 | 10x |
| Joblib | 25 | 40x |
| Numba | 5 | 200x |

![Optimization Cascade](figures/optimization_cascade.png)

### Caso 2: Regress√£o Linear

#### Problema: Ajuste de M√∫ltiplos Modelos

```python
# An√°lise de dados de ensaios de materiais
# Ajustar curvas tens√£o-deforma√ß√£o para 10.000 amostras

def fit_stress_strain(data):
    # Regress√£o linear: œÉ = E √ó Œµ + œÉ‚ÇÄ
    strain, stress = data
    coeffs = np.polyfit(strain, stress, 1)
    E_modulus = coeffs[0]  # M√≥dulo de elasticidade
    yield_stress = coeffs[1]  # Tens√£o de escoamento
    return E_modulus, yield_stress

# Vers√£o paralela com joblib
E_values, yield_values = zip(*Parallel(n_jobs=-1)(
    delayed(fit_stress_strain)(sample) 
    for sample in material_samples
))
```

### Caso 3: Simula√ß√£o Monte Carlo

#### An√°lise de Confiabilidade Estrutural

```python
@njit(parallel=True)
def reliability_analysis(n_samples):
    failures = 0
    for i in prange(n_samples):
        # Gerar propriedades aleat√≥rias
        load = np.random.normal(1000, 100)      # kN
        strength = np.random.normal(1500, 150)  # kN
        
        # Verificar falha
        if load > strength:
            failures += 1
    
    return failures / n_samples  # Probabilidade de falha
```

---

## ‚ö° Otimiza√ß√µes e Boas Pr√°ticas

### Hierarquia de Otimiza√ß√£o

1. **Algoritmo** - O(n¬≤) ‚Üí O(n log n)
2. **Vetoriza√ß√£o** - Loops ‚Üí NumPy
3. **Compila√ß√£o** - Python ‚Üí Numba
4. **Paraleliza√ß√£o** - 1 core ‚Üí n cores
5. **Hardware** - CPU ‚Üí GPU

### Numba: Do's and Don'ts

#### ‚úÖ Funciona Bem
```python
@njit
def good_for_numba():
    # Loops num√©ricos
    for i in range(n):
        arr[i] = math.sqrt(arr[i])
    
    # Opera√ß√µes matem√°ticas
    result = a * b + c * d
    
    # Arrays NumPy
    return np.sum(arr)
```

#### ‚ùå N√£o Funciona
```python
@njit  # Vai dar erro!
def bad_for_numba():
    # Strings
    message = "Hello World"
    
    # Listas Python
    my_list = [1, 2, 3]
    
    # Pandas DataFrames
    df = pd.DataFrame(data)
```

### Joblib: Configura√ß√µes Importantes

```python
# Controle de backend
results = Parallel(n_jobs=4, backend='multiprocessing')(
    delayed(func)(x) for x in data
)

# Para arrays grandes
results = Parallel(n_jobs=4, backend='threading')(
    delayed(numpy_func)(x) for x in data  # ThreadingBackend
)

# Verbose para debug
results = Parallel(n_jobs=4, verbose=10)(
    delayed(func)(x) for x in data
)
```

---

## üéØ Diretrizes para Escolha de Ferramentas

### Matriz de Decis√£o

| Caso | Ferramenta Recomendada | Justificativa |
|------|----------------------|---------------|
| **Loops simples + n√∫meros** | Numba | Speedup massivo |
| **Multiple similar tasks** | Joblib | Sintaxe simples |
| **Complex workflows** | concurrent.futures | Controle fino |
| **NumPy arrays grandes** | Threading + NumPy | GIL liberado |
| **I/O intensivo** | asyncio/threading | N√£o CPU bound |

### Fluxo de Otimiza√ß√£o

```
1. Medir performance atual (baseline)
   ‚Üì
2. Identificar gargalos (profiling)
   ‚Üì
3. Algoritmo adequado?
   ‚Üì
4. Vetorizar com NumPy
   ‚Üì
5. Numba para loops cr√≠ticos
   ‚Üì
6. Paralelizar tarefas independentes
   ‚Üì
7. Medir novamente e comparar
```

---

## üìä M√©tricas e Benchmarking

### Ferramentas de Medi√ß√£o

```python
import time
import psutil
import sys

def benchmark(func, *args, **kwargs):
    # Mem√≥ria antes
    mem_before = psutil.Process().memory_info().rss / 1024 / 1024
    
    # Tempo de execu√ß√£o
    start = time.perf_counter()
    result = func(*args, **kwargs)
    end = time.perf_counter()
    
    # Mem√≥ria depois
    mem_after = psutil.Process().memory_info().rss / 1024 / 1024
    
    print(f"Tempo: {end - start:.3f}s")
    print(f"Mem√≥ria: {mem_after - mem_before:.1f} MB")
    
    return result
```

### Reporting Estruturado

```python
def scaling_study(func, data_sizes, max_workers=8):
    results = []
    
    for size in data_sizes:
        for workers in range(1, max_workers + 1):
            time_taken = measure_time(func, size, workers)
            
            results.append({
                'size': size,
                'workers': workers,
                'time': time_taken,
                'speedup': results[0]['time'] / time_taken,
                'efficiency': speedup / workers
            })
    
    return pd.DataFrame(results)
```

---

## üö® Pitfalls Comuns

### 1. Over-parallelization
```python
# ‚ùå Ruim: overhead > benef√≠cio
for small_task in tiny_tasks:
    executor.submit(small_task)

# ‚úÖ Bom: batch pequenas tarefas
batched_tasks = [tiny_tasks[i:i+100] for i in range(0, len(tiny_tasks), 100)]
for batch in batched_tasks:
    executor.submit(process_batch, batch)
```

### 2. Memory Explosion
```python
# ‚ùå Ruim: cada processo copia tudo
big_array = np.random.rand(10000, 10000)  # 800 MB

with ProcessPoolExecutor(max_workers=8) as executor:
    # 8 processos √ó 800 MB = 6.4 GB!
    futures = [executor.submit(process, big_array, i) for i in range(tasks)]
```

### 3. Shared State Problems
```python
# ‚ùå Problem√°tico: estado compartilhado
global_counter = 0

def increment():
    global global_counter
    global_counter += 1  # Race condition!

# ‚úÖ Melhor: evitar estado global
def process_with_result(data):
    # Retornar resultados, n√£o modificar globais
    return processed_data
```

---

## üéØ Pontos Principais para Recordar

### Ferramentas e Quando Usar

1. **Numba**: Loops num√©ricos intensivos (10-200x speedup)
2. **Joblib**: M√∫ltiplas tarefas similares (sintaxe simples)  
3. **concurrent.futures**: Controle fino e workflows complexos
4. **Threading**: I/O intensivo ou NumPy (libera GIL)

### Scaling e Performance

1. **Strong scaling**: Problema fixo, mais recursos
2. **Weak scaling**: Mais trabalho, mais recursos
3. **Efici√™ncia > 60%**: Boa paraleliza√ß√£o
4. **Benchmark sempre**: Medir antes e depois

### Otimiza√ß√£o Hier√°rquica

1. **Algoritmo** primeiro (maior impacto)
2. **Vetoriza√ß√£o** com NumPy
3. **Compila√ß√£o** com Numba  
4. **Paraleliza√ß√£o** por √∫ltimo

---

## üöÄ Pr√≥ximos Passos

### Nesta Aula
- Experimentar com joblib e numba
- Fazer scaling studies
- Comparar diferentes abordagens

### Pr√≥xima Aula (GPU Computing)
- **CuPy**: NumPy para GPU
- **Numba CUDA**: Kernels customizados
- **Performance**: CPU vs GPU

### Projeto Final
- Aplicar todas as t√©cnicas
- An√°lise completa de performance
- Scaling study abrangente

---

## ‚ùì Perguntas para Reflex√£o

1. **Quando Numba n√£o ajuda?** Que tipos de c√≥digo n√£o se beneficiam?

2. **Trade-offs**: Simplicidade (joblib) vs Controle (futures)?

3. **Scaling ideal**: Como identificar o n√∫mero √≥timo de workers?

4. **Bottlenecks**: Como identificar se √© CPU, mem√≥ria ou I/O?

**Desafio**: Escolha um algoritmo lento do seu trabalho e aplique as t√©cnicas desta aula!

---

**Vamos para o Notebook! üíª**